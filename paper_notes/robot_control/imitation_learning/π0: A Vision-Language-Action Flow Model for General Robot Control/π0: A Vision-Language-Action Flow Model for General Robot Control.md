# π0: A Vision-Language-Action Flow Model for General Robot Control
[toc]
![图1](image.png)
图1：我们的一般性机器人策略采用了一个预训练的视觉-语言模型（VLM）作为基础架构，同时使用了一个多样化的跨实体数据集，该数据集包含各种灵巧的操作任务。通过添加一个单独的动作专家，该模型被适应于机器人控制，该专家通过*流匹配（flow matching）*产生连续的动作，从而实现精确和流畅的操作技能。随后，该模型可以被用于零样本控制，或者在高质量数据上进行微调，以执行复杂的多阶段任务，比如折叠多件洗衣或组装一个盒子。
## abstract
机器人学习具有巨大的潜力，可以释放灵活、通用和灵巧机器人系统的全部潜能，并解决人工智能中一些最深层次的问题。然而，将机器人学习提升到现实世界系统所需的通用性水平时，面临数据、泛化和鲁棒性等重大障碍。在本文中，我们讨论了**通用机器人策略**（即机器人基础模型）如何应对这些挑战，以及如何为复杂且高度灵巧的任务设计有效的通用机器人策略。我们提出了一个基于**预训练视觉-语言模型（VLM）** 的新颖**流匹配**架构，以继承互联网规模的语义知识。然后，我们讨论了如何在多个灵巧机器人平台的大型和多样化数据集上对该模型进行训练，包括单臂机器人、双臂机器人以及移动操作器。我们根据模型在预训练后进行零样本任务的能力、遵循人们和高层VLM策略的语言指令的能力，以及通过微调获取新技能的能力来评估我们的模型。我们的结果涵盖了多种任务，如叠衣服、清理桌面和组装盒子。
![图2](image-1.png)
图2： π0控制一个移动操作器进行叠衣服。我们的模型在7种不同的机器人配置和68个任务的多样化数据上进行了预训练，随后可以用于零样本或微调到复杂的下游任务，如本例中的叠衣服策略，该策略从干衣机中取出衣服，将其装入衣篮中，将衣篮带到折叠桌前，然后折叠每件衣服。
## introduction
人工智能系统形式多样，从解决人类思维无法触及的复杂问题的高度专业化系统，如预测蛋白质的构象[21]，到能够根据文本提示生成逼真高分辨率图像或视频的系统[40]。然而，人类智能在多样性上超越机器智能的轴线是灵活性：在各种物理环境中解决多样化任务的能力，同时智能地应对环境限制、语言命令和意外的扰动。AI在这种灵活性上的最明显进展可能出现在大型语言和视觉-语言模型[1, 48]上：这些系统在大规模、极具多样性的互联网图片和文本语料库上进行预训练，然后使用更精心挑选的数据集进行微调（“对齐”），以诱导所需的行为模式和响应性。尽管这些模型已显示出广泛的指令遵循和问题解决能力[53, 27]，但它们并不真正像人那样处于物理世界中，它们对物理交互的理解完全基于抽象描述。如果这些方法要在展现人类所具备的物理环境中的灵活性方面取得实质性进展，我们需要在物理环境的数据上对它们进行训练——即来自具身机器人代理的数据。

灵活且通用的模型能够执行各种机器人行为的任务具有巨大的实际意义，但它们也可能为机器人学习今天面临的一些最艰难的挑战提供解决方案，如数据可用性、泛化和鲁棒性。在自然语言[1]和计算机视觉[39]中，**在多任务数据上预训练的通用基础模型往往优于专门定制和专业化的解决方案** 例如，如果目标是识别照片中的鸟类，可能更有效的是在许多不同的图像-语言关联上进行预训练，然后针对鸟类识别任务进行微调或提示，而不是仅在鸟类识别数据上进行训练。同样，我们可能发现，**对于有效的专业机器人系统，首先在大规模多样化的机器人数据上进行预训练，然后针对所需任务进行微调或提示可能更有效。** 这可以解决数据稀缺问题，因为对于通用模型来说，有更多的数据来源可供使用——包括来自其他任务、其他机器人甚至非机器人的来源——并且它可能解决鲁棒性和泛化问题，因为多样化数据展示了更广泛的观察和行动覆盖，提供了各种场景、校正和恢复行为，这些在更狭窄的专业化数据中可能并不存在。因此，采用大规模预训练方法来进行机器人学习有潜力解决该领域的许多挑战，并使实用的学习型机器人成为现实，同时进一步加深我们对人工智能中最深层次问题的理解。

然而，开发这种通用机器人策略——即机器人基础模型——涉及一系列重大挑战。**首先** ，任何此类研究都必须在**大规模**上进行，因为大规模预训练的全部好处在较小规模上往往并不明显[54]。**其次**，需要开发能够**有效利用多样化数据源的正确模型架构**，同时**能够表示与复杂物理场景交互所需的复杂和微妙的行为**。**第三**，需要**正确的训练配方**。这可能是最重要的成分，因为近期在NLP和计算机视觉中大型模型的进步很大程度上依赖于精心策划的预训练和后训练数据策略[35]。

在本文中，我们提出了一种原型模型和学习框架，我们称之为**π0**，它展示了如何解决这三个瓶颈中的每一个。我们在图1中展示了我们的模型和系统。为了**整合多样化数据源**，我们首先利用**预训练的视觉-语言模型(VLM)** 导入互联网规模的经验。通过基于VLM构建我们的模型，我们继承了语言和视觉-语言模型的一般知识、语义推理和问题解决能力。然后，我们进一步训练我们的模型以整合机器人动作，将其变成一个**视觉-语言-动作（VLA）模型**[7]。为了使利用**多样化机器人数据源**成为可能，我们采用了**跨实体训练**[10]，其中**许多类型的机器人数据被合并到同一个模型中**。这些不同类型的机器人具有不同的配置空间和动作表示，包括单臂和双臂系统，以及移动操作器。此外，为了能够执行高度灵巧和复杂的物理任务，我们使用了**动作分块架构[57]结合流匹配**（扩散的一种变体）来表示**复杂的连续动作分布**[28, 32]。这使我们的模型能够以高达**50 Hz**的频率控制机器人执行如叠衣服等灵巧任务（见图1）。为了将流匹配与VLM结合起来，我们使用了一个新的**动作专家**，它通过**流匹配输出**增强了标准的VLM。

正如语言模型一样，我们模型的架构只是我们方法的一部分。为了灵活且稳健地执行复杂任务，我们需要正确的训练配方。我们的配方反映了在超大规模语言和图像-语言模型中常见的预训练/后训练分离[1, 48]，其中模型**首先在大规模、极具多样性的语料库上进行预训练**，**然后在更狭窄、更精心挑选的数据上进行微调**，以诱导所需的行为模式——在我们的案例中，是灵巧性、效率和鲁棒性。从直观上讲，仅在高质量数据上进行训练并不会教会模型如何从错误中恢复，因为在这种数据中很少见到错误。仅在较低质量预训练数据上进行训练并不会教会模型高效且稳健地行动。结合两者提供了所需的行为：模型尽可能地以类似高质量数据的方式行动，但仍有一套恢复和校正的策略可在出错时部署。

我们工作的贡献包括基于**VLM预训练**和**流匹配的新颖通用机器人策略架构**，以及对这种**机器人基础模型的预训练/后训练配方的实证研究**。我们评估了我们的模型在**零样本控制**、**语言命令下**、**微调到下游任务**以及**结合输出中间语言命令执行复杂和时间扩展任务**的高级语义策略的表现。虽然我们的模型和系统使用了近期工作中提出的各种想法，但成分的组合是新的，实证评估显示出一种超越之前展示的机器人基础模型的灵巧性和通用性。我们通过在超过10,000小时的机器人数据上进行预训练，并微调到各种灵巧任务来评估我们的方法，包括叠衣服（见图2）、清理桌子、将盘子放入微波炉、将鸡蛋装入纸板盒、组装盒子和打包杂货。

## related works
我们的工作建立在最近提出的大规模机器人学习方法以及多模态语言模型之上。我们的工作与最近提出的**视觉-语言-动作（VLA）** 模型最密切相关，这些模型使用针对机器人控制进行微调的预训练VLM[7, 24, 55]。这些模型采用自回归离散化来以类似文本标记的方式表示动作。相比之下，我们的模型采用了一种新颖的设计，通过**流匹配**[32, 28]（扩散的一种变体[20, 46]）**微调VLM来产生动作**。这使我们能够**处理高频率的动作块**[57]（高达50 Hz）和**高度灵巧的任务**，我们展示了这些任务对之前的自回归VLA[7]构成了重大挑战。这类似于近期关于用于动作生成的扩散模型的多项工作[9, 60]。与这些工作相反，我们的模型使用了一个预训练的VLM骨干[5]。我们的贡献还具有根本的整合性，专注于机器人基础模型的框架，包括不仅模型架构本身，还包括预训练配方、预训练和后训练阶段，以及一系列现实世界的实验。

在机器人控制之外，许多模型已经提出，将预训练的语言模型与扩散结合起来[40, 41, 14]，包括专门混合扩散和自回归大型语言模型的模型[19, 29, 59]。这些模型通常关注图像生成，但我们的动作生成模型建立在之前提出的多个概念之上。像Zhou等人[59]一样，我们通过**在单个序列元素上应用扩散风格（流匹配）的损失**来训练我们的模型，以替代仅解码器变换器的标准交叉熵损失。像Liu等人[29]一样，我们为对应于扩散的标记使用了一组单独的权重。在将这些概念融入VLA模型中，我们引入了我们所知**第一个为灵巧控制产生高频率动作块的流匹配VLA**。

我们的工作也建立在一个丰富的历史上，关于大规模机器人学习的先前工作。该领域的早期工作通常利用自监督或自主数据收集[26, 22, 8]，为抓取[18, 37]或推动[56]等简单任务提供了可行的数据源，但没有更灵巧行为的复杂性。最近，一些高质量的数据集已被收集用于机器人控制，允许广泛的泛化[23, 10, 52, 33, 34, 43, 13, 6]，但通常是对于更简单的任务，这些任务包括物体重新定位和初级家具操作（例如，开抽屉）[31, 15]。更灵巧的任务已在较小的规模上进行研究，通常有10或100个训练轨迹[57]，相当于10小时或更少。由于我们的目标之一是研究复杂和灵巧的行为，我们利用了一个**更大的数据集**，大约有**10,000小时**的示范，并结合了**开源的OXE数据集**[10]。据我们所知，这代表了**迄今为止在机器人数据量方面的最大机器人学习实验**。在这个规模上，我们展示了一个更复杂的预训练/后训练配方非常有效——类似于用于大型语言模型的配方，预训练阶段赋予我们的模型广泛的基础知识，然后在后训练阶段通过更高质量的精心挑选数据来细化，以实现所需的行为。

我们展示的任务的复杂性远远超出了之前的工作。虽然最近的工作展示了许多更复杂和灵巧的行为，如系鞋带[58]或煮虾[17]，但我们展示了我们的框架可以**训练非常长的任务**，有时长达几分钟的任务，这些任务结合了物理灵巧性和组合复杂性。例如，我们的叠衣服任务要求机器人操作各种可能从任何配置开始的衣物，并连续折叠多个物品。我们的清理桌子任务需要辨别新对象的类别（垃圾或盘子）。我们展示了一个单一的跨实体模型可以用作这些任务的基础模型。据我们所知，我们的工作展示了端到端机器人学习文献中最长的灵巧任务。