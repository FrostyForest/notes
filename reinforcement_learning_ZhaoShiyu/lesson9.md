# lecture 9 Policy Gradient Methods
[toc]
## Basic idea
![previous method](image-187.png)
![functions](image-188.png)
![differences between tabular and functions](image-189.png)
![second](image-190.png)
![third](image-191.png)
![summary](image-192.png)
## Metric1-Average value
![first metric](image-193.png)
![vector-product form](image-194.png)
![how to select distribution](image-195.png)
![how to select distribution-2](image-196.png)
## Metric2-Average reward
![second metric](image-197.png)
![definition](image-198.png)
![property](image-199.png)
![remarks](image-200.png)
![remark2](image-201.png)
![remark3](image-202.png)
![transition](image-203.png)
![ans](image-204.png)
## Gradients of the metrics
![summary](image-205.png)
![results](image-206.png)
### useful form of gradient 
![useful form of gradient](image-207.png)
### proven
![proven](image-208.png)
![prove2](image-209.png)
![remarks](image-210.png)
![remarks2](image-211.png)
## Gradient-based algorithms reinforce
![al](image-212.png)
![al2](image-213.png)
![rm1](image-214.png)
![rm2](image-215.png)
![maximizing$\pi$](image-216.png)
### $\beta$的理解
![beta的理解](image-217.png)
### REINFORCE
![REINFORCE](image-218.png)
![pseudocode](image-219.png)
